
 <!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="UTF-8">
  
    <title>卷积神经网络 | Lightman&#39;s blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Lightman">
    

    
    <meta name="description" content="1. 简介 卷积神经网络的一般结构：conv-&gt;pool-&gt;conv-&gt;pool-&gt;fc-&gt;fc-&gt;fc-&gt;softmax  conv：卷积层 pool：池化层 fc：全连接层 softmax：分类函数   各层的作用：  卷积层作用：可以使用卷积来提取自己想要的特征 池化层作用：对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积神经网络">
<meta property="og:url" content="http://yoursite.com/2019/12/23/CNN/index.html">
<meta property="og:site_name" content="Lightman&#39;s blog">
<meta property="og:description" content="1. 简介 卷积神经网络的一般结构：conv-&gt;pool-&gt;conv-&gt;pool-&gt;fc-&gt;fc-&gt;fc-&gt;softmax  conv：卷积层 pool：池化层 fc：全连接层 softmax：分类函数   各层的作用：  卷积层作用：可以使用卷积来提取自己想要的特征 池化层作用：对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-12-22T16:12:21.000Z">
<meta property="article:modified_time" content="2019-12-30T16:48:51.189Z">
<meta property="article:author" content="Lightman">
<meta property="article:tag" content="CNN">
<meta name="twitter:card" content="summary">

    
    <link rel="alternative" href="/atom.xml" title="Lightman&#39;s blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    
<link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/%02.css">
<link rel="stylesheet" href="/.css">

<meta name="generator" content="Hexo 4.2.1"></head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Lightman&#39;s blog" title="Lightman&#39;s blog"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Lightman&#39;s blog">Lightman&#39;s blog</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:yoursite.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2019/12/23/CNN/" title="卷积神经网络" itemprop="url">卷积神经网络</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Lightman" target="_blank" itemprop="author">Lightman</a>
		
  <p class="article-time">
    <time datetime="2019-12-22T16:12:21.000Z" itemprop="datePublished"> Published 2019-12-23</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-简介"><span class="toc-number">1.</span> <span class="toc-text">1. 简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-代码"><span class="toc-number">2.</span> <span class="toc-text">2. 代码</span></a></li></ol>
		
		</div>
		
		<h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><ul>
<li><p><strong>卷积神经网络的一般结构：</strong>conv-&gt;pool-&gt;conv-&gt;pool-&gt;fc-&gt;fc-&gt;fc-&gt;softmax</p>
<ul>
<li>conv：卷积层</li>
<li>pool：池化层</li>
<li>fc：全连接层</li>
<li>softmax：分类函数</li>
</ul>
</li>
<li><p><strong>各层的作用：</strong></p>
<ul>
<li><strong>卷积层作用：</strong>可以使用卷积来提取自己想要的特征</li>
<li><strong>池化层作用：</strong>对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征。主要分为两类<ul>
<li>最大池化层：把每个区域的最大值输出</li>
<li>平均池化层：把每个区域的平均值输出</li>
</ul>
</li>
<li><strong>全连接层作用:</strong>连接所有特征，将输出值送给分类器</li>
</ul>
</li>
</ul>
<h2 id="2-代码"><a href="#2-代码" class="headerlink" title="2. 代码"></a>2. 代码</h2><ul>
<li><p><strong>导入数据</strong></p>
<pre><code>#导入input_data用于自动下载和安装MNIST数据集
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)

#创建两个占位符，x为输入网络的图像，y_为输入网络的图像类别
x = tf.placeholder(&quot;float&quot;, shape=[None, 784])
y_ = tf.placeholder(&quot;float&quot;, shape=[None, 10])</code></pre><p>  导入MNIST数据集，并设置占位符来保存图片数据和预测信息</p>
</li>
<li><p><strong>初始化函数</strong></p>
<pre><code>#权重初始化函数
def weight_variable(shape):
    #输出服从截尾正态分布的随机值
    initial = tf.truncated_normal(shape, stddev=0.1)
    return tf.Variable(initial)

#偏置初始化函数
def bias_variable(shape):
    initial = tf.constant(0.1, shape=shape)
    return tf.Variable(initial)</code></pre><p>  这里使用了函数来对权重和偏置进行初始化。</p>
</li>
<li><p><strong>卷积层和池化层函数</strong></p>
<pre><code>#创建卷积op
#x 是一个4维张量，shape为[batch,height,width,channels]
#卷积核移动步长为1。填充类型为SAME,可以不丢弃任何像素点, VALID丢弃边缘像素点
def conv2d(x, W):
    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=&quot;SAME&quot;)

#创建池化op
#采用最大池化，也就是取窗口中的最大值作为结果
#x 是一个4维张量，shape为[batch,height,width,channels]
#ksize表示pool窗口大小为2x2,也就是高2，宽2
#strides，表示在height和width维度上的步长都为2
def max_pool_2x2(x):
    return tf.nn.max_pool(x, ksize=[1,2,2,1],
                          strides=[1,2,2,1], padding=&quot;SAME&quot;)</code></pre><ul>
<li>卷积层参数介绍：<ul>
<li>x为输入的数据，shape为[batch,height,width,channels]，batch的数量，高和宽，以及它的通道数，这里使用的数据集的图片通道是1</li>
<li>W为权重矩阵，这里的权重矩阵就是卷积核(过滤器)中的参数信息，举例：假如是5*5的过滤器，那么参数就有25个</li>
<li>strides是步长，可以使一个实数也可以是一个4维向量，第一和第四默认为1（不知道具体意思，官方文档也没有介绍，好像是和通道有关），第二个为横向步长，第二个为纵向步长，这里表示在height和width维度上的步长都为1</li>
<li>padding：有两个参数’same’和’valid’，’same’表示不舍弃边缘信息，’vaild’表示舍弃边缘信息.</li>
</ul>
</li>
<li>池化层参数介绍：<ul>
<li>x，strides和padding与卷积层的作用一样，这里strides表示在height和width维度上的步长都为2</li>
<li>ksize表示的是池化层的大小，这里是高2，宽2</li>
<li>这里使用的是最大池化层，也就是去窗口中的最大值作为结果</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>第一层卷积层</strong></p>
<pre><code>#第1层，卷积层
#初始化W为[5,5,1,6]的张量，表示卷积核大小为5*5，1表示图像通道数，6表示卷积核个数即输出6个特征图
W_conv1 = weight_variable([5,5,1,6])
#初始化b为[6],即输出大小
b_conv1 = bias_variable([6])

#把输入x(二维张量,shape为[batch, 784])变成4d的x_image，x_image的shape应该是[batch,28,28,1]
#-1表示自动推测这个维度的size
x_image = tf.reshape(x, [-1,28,28,1])

#把x_image和权重进行卷积，加上偏置项，然后应用ReLU激活函数，最后进行max_pooling
#h_pool1的输出即为第一层网络输出，shape为[batch,14,14,6]
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1)</code></pre><ul>
<li>使用的卷积核(过滤器)是高宽5*5，通道1，一共有6个卷积核，偏置的数量要与卷积核数量相等，所以也是6</li>
<li>因为要求输入的数据是[batch,height,width,channels]，而数据集的数据x是[batch, 784]，所以要reshape。-1表示自动推测这个维度的size，比如，x是一组图像的矩阵（BATCH_SIZE=100，大小为28×28），则执行x_image = tf.reshape(x, [-1, 28, 28，1])可以计算a=100×28×28/28/28/1=100。即image的维数为（100，28，28）。</li>
<li>把x_image和权重进行卷积，加上偏置项，然后应用ReLU激活函数，最后进行max_pooling，形成第一层卷积层</li>
<li>当池化层为2*2时，输出的图像高和宽会缩减一半，所以第一层网络输出，shape为[batch,14,14,6]，6是因为有6个卷积核，一个卷积核输出一个结果，最后6个结果叠到一起形成最终结果</li>
</ul>
</li>
<li><p><strong>第二层卷积层</strong></p>
<pre><code>#第2层，卷积层
#卷积核大小依然是5*5，通道数为6，卷积核个数为16
W_conv2 = weight_variable([5,5,6,16])
b_conv2 = weight_variable([16])

#h_pool2即为第二层网络输出，shape为[batch,7,7,16]
h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)</code></pre><ul>
<li>卷积核5*5，通道数因为要与输入的数据的通道数相同，所以这里是6，卷积核数量为16</li>
<li>其他的与第一层大致相同</li>
</ul>
</li>
<li><p><strong>全连接层</strong></p>
<pre><code>#第3层, 全连接层
#这层是拥有120个神经元的全连接层
#W的第1维size为7*7*16，7*7是h_pool2输出的size，16是第2层输出神经元个数
W_fc1 = weight_variable([7*7*16, 120])
b_fc1 = bias_variable([120])

#计算前需要把第2层的输出reshape成[batch, 7*7*16]的张量
h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*16])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)

#Dropout层
#为了减少过拟合，在输出层前加入dropout
keep_prob = tf.placeholder(&quot;float&quot;)
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</code></pre><ul>
<li>全连接层，是一个标准的神经网络层</li>
<li>我们要想把上一个卷积层的输出reshape成一个1维列向量，7<em>7</em>16</li>
<li>该层的神经元数是120个，所以权重矩阵为[7<em>7</em>16,120]</li>
<li>为了防止过拟合加入了dropout层</li>
</ul>
</li>
<li><p><strong>输出层(softmax层)</strong></p>
<pre><code>#输出层
#最后，添加一个softmax层
#可以理解为另一个全连接层，只不过输出时使用softmax将网络输出值转换成了概率
W_fc2 = weight_variable([120, 10])
b_fc2 = bias_variable([10])

y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)</code></pre><ul>
<li>因为手写数字有10个，所以最后的权重是[120,10]</li>
</ul>
</li>
<li><p><strong>定义损失函数和梯度下降</strong></p>
<pre><code>cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))

#train op, 使用ADAM优化器来做梯度下降。学习率为0.0001
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)

#评估模型，tf.argmax能给出某个tensor对象在某一维上数据最大值的索引。
#因为标签是由0,1组成了one-hot vector，返回的索引就是数值为1的位置
correct_predict = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))

#计算正确预测项的比例，因为tf.equal返回的是布尔值，
#使用tf.cast把布尔值转换成浮点数，然后用tf.reduce_mean求平均值
accuracy = tf.reduce_mean(tf.cast(correct_predict, &quot;float&quot;))</code></pre><ul>
<li>使用交叉熵来定义损失函数</li>
<li>计算算法的准确率</li>
</ul>
</li>
<li><p><strong>训练和预测</strong></p>
<pre><code>saver = tf.train.Saver()

#开始训练模型，循环20000次，每次随机从训练集中抓取50幅图像
def cnn_train():
    # 创建一个交互式Session
    sess = tf.InteractiveSession()
    sess.run(tf.initialize_all_variables())
    for i in range(20000):
        batch = mnist.train.next_batch(50)
        if i%100 == 0:
            #每100次输出一次日志
            train_accuracy = accuracy.eval(feed_dict={
                x:batch[0], y_:batch[1], keep_prob:1.0})
            print (&quot;step %d, training accuracy %g&quot; % (i, train_accuracy))
            saver.save(sess, &apos;./model&apos;)
        train_step.run(feed_dict={x:batch[0], y_:batch[1], keep_prob:0.5})

#预测
def predict():
    sess = tf.InteractiveSession()
    sess.run(tf.global_variables_initializer())
    saver = tf.train.Saver(tf.global_variables())
    saver.restore(sess, &apos;model&apos;)
    print( &quot;test accuracy %g&quot; % accuracy.eval(feed_dict={
        x:mnist.test.images, y_:mnist.test.labels, keep_prob:1.0}))</code></pre><ul>
<li>这里创建了一个Saver类来保存训练好的模型</li>
<li>创建了一个开放的会话，InteractiveSession来保证在运行图的时候，可以随时插入一些计算图，Session要求必须在会话构建之前定义好全部的操作</li>
</ul>
</li>
<li><p><strong>使用</strong></p>
<pre><code>cnn_train()
predict()</code></pre><ul>
<li>由于我在运行时保存了模型，所以在运行时可以吧cnn_train()注释掉，直接运行，可以省略训练过程，如果想查看训练过程可以直接运行</li>
</ul>
</li>
</ul>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">

<div class="article-categories">
  <span></span>
  <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
</div>


  <div class="article-tags">
  
  <span></span> <a href="/tags/CNN/">CNN</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://yoursite.com/2019/12/23/CNN/" data-title="卷积神经网络 | Lightman&#39;s blog" data-tsina="" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2019/12/23/CNNAutoEncoder/" title="卷积自编码器">
  <strong>上一篇：</strong><br/>
  <span>
  卷积自编码器</span>
</a>
</div>


<div class="next">
<a href="/2019/12/23/EnglishPronunciation/"  title="连读规则">
 <strong>下一篇：</strong><br/> 
 <span>连读规则
</span>
</a>
</div>

</nav>

	



</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-简介"><span class="toc-number">1.</span> <span class="toc-text">1. 简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-代码"><span class="toc-number">2.</span> <span class="toc-text">2. 代码</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  


  
<div class="categorieslist">
	<p class="asidetitle">Categories</p>
		<ul>
		
		  
			<li><a href="/categories/前端技术/" title="前端技术">前端技术<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/后台技术/" title="后台技术">后台技术<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/常用技术/" title="常用技术">常用技术<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/强化学习/" title="强化学习">强化学习<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/深度学习/" title="深度学习">深度学习<sup>7</sup></a></li>
		  
		
		  
			<li><a href="/categories/算法/" title="算法">算法<sup>1</sup></a></li>
		  
		
		  
			<li><a href="/categories/英语/" title="英语">英语<sup>3</sup></a></li>
		  
		
		  
			<li><a href="/categories/读书笔记/" title="读书笔记">读书笔记<sup>1</sup></a></li>
		  
		
		</ul>
</div>


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/AutoEncoder/" title="AutoEncoder">AutoEncoder<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/CNN/" title="CNN">CNN<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/连读发音/" title="连读发音">连读发音<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/GAN/" title="GAN">GAN<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/协作开发软件/" title="协作开发软件">协作开发软件<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Flex/" title="Flex">Flex<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/JavaScript/" title="JavaScript">JavaScript<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/LSTM/" title="LSTM">LSTM<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Ted/" title="Ted">Ted<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Typescript/" title="Typescript">Typescript<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Q网络/" title="Q网络">Q网络<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/GCN/" title="GCN">GCN<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/电影台词/" title="电影台词">电影台词<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/沉默的大多数/" title="沉默的大多数">沉默的大多数<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/算法/" title="算法">算法<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Python/" title="Python">Python<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="https://coderq.com" target="_blank" title="一个面向程序员交流分享的新一代社区">码农圈</a>
            
          </li>
        
          <li>
            
            	<a href="http://wuchong.me" target="_blank" title="Jark&#39;s Blog">Jark&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">Weibo</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=&verifier=b3593ceb&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Larry Page in Google. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/2176287895" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2020 
		
		<a href="/about" target="_blank" title="Lightman">Lightman</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>











<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
