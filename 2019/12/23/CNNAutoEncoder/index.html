<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>卷积自编码器 | Lightman&#39;s blog</title>
  <meta name="keywords" content=" AutoEncoder , CNN ">
  <meta name="description" content="卷积自编码器 | Lightman&#39;s blog">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="1. 简介 作用：为了解决RNN存在的梯度消失问题，即无法实现对某些信息实现长期保存  原理：简单来说就是给RNN加上了一些记忆控制器，使用Forget Gate,Input Gate,Output Gate来控制信息的流动程度。如图： ![][Specify]  上一个LSTM单元得到一个信息a&lt;t-1&gt;，与这个单元的输入x&lt;t&gt;，通过forget门，使用sigmoid函">
<meta property="og:type" content="article">
<meta property="og:title" content="LSTM简介及代码">
<meta property="og:url" content="http://yoursite.com/2019/12/23/LSTM/index.html">
<meta property="og:site_name" content="Lightman&#39;s blog">
<meta property="og:description" content="1. 简介 作用：为了解决RNN存在的梯度消失问题，即无法实现对某些信息实现长期保存  原理：简单来说就是给RNN加上了一些记忆控制器，使用Forget Gate,Input Gate,Output Gate来控制信息的流动程度。如图： ![][Specify]  上一个LSTM单元得到一个信息a&lt;t-1&gt;，与这个单元的输入x&lt;t&gt;，通过forget门，使用sigmoid函">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-12-22T16:12:21.000Z">
<meta property="article:modified_time" content="2019-12-30T16:48:46.380Z">
<meta property="article:author" content="Lightman">
<meta property="article:tag" content="LSTM">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.0.1" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.0.1" rel="stylesheet">

<link href="//cdn.bootcss.com/animate.css/3.5.2/animate.min.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="/js/jquery.autocomplete.min.js?v=1.0.1" ></script>

<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>



<script src="//cdn.bootcss.com/jquery-cookie/1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.0.1" ></script>

<meta name="generator" content="Hexo 4.2.0"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="false">
  <input class="theme_blog_path" value="">
</div>

<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/" class="avatar_target">
    <img class="avatar" src="/img/avatar.jpg" />
</a>
<div class="author">
    <span>Lightman</span>
</div>

<div class="icon">
    
</div>




<ul>
    <li><div class="all active">全部文章<small>(17)</small></div></li>
    
        
            
            <li><div data-rel="深度学习">深度学习<small>(7)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="英语">英语<small>(2)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="前端技术">前端技术<small>(3)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="常用技术">常用技术<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="强化学习">强化学习<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="后台技术">后台技术<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="算法">算法<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="读书笔记">读书笔记<small>(1)</small></div>
                
            </li>
            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
    
    
    
    
    </div>
    <div></div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="17">

<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="back-title-list"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://yelog.org/">叶落阁</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <form onkeydown="if(event.keyCode==13){return false;}">
        <input class="search" type="text" placeholder="Search..." autocomplete="off"id="local-search-input" >
        <i class="cross"></i>
        <span>
            <label for="tagswitch">Tags:</label>
            <input id="tagswitch" type="checkbox" style="display: none" />
            <i id="tagsWitchIcon"></i>
        </span>
    </form>
    <div class="tags-list">
    
    <li class="article-tag-list-item">
        <a class="color2">AutoEncoder</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">连读发音</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">Flex</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color4">CNN</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color4">GAN</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">JavaScript</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">协作开发软件</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">LSTM</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color4">Q网络</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color4">GCN</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color4">Ted</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color4">Vue</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">Python</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">算法</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">沉默的大多数</a>
    </li>
    
    <div class="clearfix"></div>
</div>

    
    <nav id="title-list-nav">
        
        <a  class="深度学习 "
           href="/2019/12/23/AdvancedAutoEncoder/"
           data-tag="AutoEncoder"
           data-author="" >
            <span class="post-title" title="AdvancedAutoEncoder">AdvancedAutoEncoder</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="英语 "
           href="/2019/12/23/EnglishPronunciation/"
           data-tag="连读发音"
           data-author="" >
            <span class="post-title" title="连读规则">连读规则</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="前端技术 "
           href="/2019/01/23/Flex/"
           data-tag="Flex"
           data-author="" >
            <span class="post-title" title="Flex 布局">Flex 布局</span>
            <span class="post-date" title="2019-01-23 00:12:21">2019/01/23</span>
        </a>
        
        <a  class="深度学习 "
           href="/2019/12/23/CNN/"
           data-tag="CNN"
           data-author="" >
            <span class="post-title" title="卷积神经网络">卷积神经网络</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="深度学习 "
           href="/2019/12/23/AutoEncoder/"
           data-tag="AutoEncoder"
           data-author="" >
            <span class="post-title" title="AutoEncoder">AutoEncoder</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="深度学习 "
           href="/2019/12/23/GAN/"
           data-tag="GAN"
           data-author="" >
            <span class="post-title" title="GAN网络代码">GAN网络代码</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="前端技术 "
           href="/2019/12/23/JavaScript%E9%AB%98%E7%BA%A7%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/"
           data-tag="JavaScript"
           data-author="" >
            <span class="post-title" title="JavaScript 高级程序设计">JavaScript 高级程序设计</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="常用技术 "
           href="/2019/12/23/Git/"
           data-tag="协作开发软件"
           data-author="" >
            <span class="post-title" title="Git教程">Git教程</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="深度学习 "
           href="/2019/12/23/LSTM/"
           data-tag="LSTM"
           data-author="" >
            <span class="post-title" title="LSTM简介及代码">LSTM简介及代码</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="深度学习 "
           href="/2019/12/23/CNNAutoEncoder/"
           data-tag="AutoEncoder,CNN"
           data-author="" >
            <span class="post-title" title="卷积自编码器">卷积自编码器</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="强化学习 "
           href="/2019/12/23/ReinforcementLearning/"
           data-tag="Q网络"
           data-author="" >
            <span class="post-title" title="强化学习简介">强化学习简介</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="深度学习 "
           href="/2019/12/23/STGCN/"
           data-tag="GCN"
           data-author="" >
            <span class="post-title" title="时空图卷积网络">时空图卷积网络</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="英语 "
           href="/2019/12/23/Ted_%E7%BB%99%E9%99%8C%E7%94%9F%E4%BA%BA%E7%9A%84%E6%83%85%E4%B9%A6/"
           data-tag="Ted"
           data-author="" >
            <span class="post-title" title="汉娜·布伦雪尔：给陌生人的情书">汉娜·布伦雪尔：给陌生人的情书</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="前端技术 "
           href="/2019/12/23/Vue/"
           data-tag="Vue"
           data-author="" >
            <span class="post-title" title="Vue学习笔记">Vue学习笔记</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="后台技术 "
           href="/2019/12/23/python/"
           data-tag="Python"
           data-author="" >
            <span class="post-title" title="Python教程">Python教程</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="算法 "
           href="/2019/12/23/%E7%AE%97%E6%B3%95/"
           data-tag="算法"
           data-author="" >
            <span class="post-title" title="算法速查">算法速查</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
        <a  class="读书笔记 "
           href="/2019/12/23/%E6%B2%89%E9%BB%98%E7%9A%84%E5%A4%A7%E5%A4%9A%E6%95%B0/"
           data-tag="沉默的大多数"
           data-author="" >
            <span class="post-title" title="沉默的大多数">沉默的大多数</span>
            <span class="post-date" title="2019-12-23 00:12:21">2019/12/23</span>
        </a>
        
    </nav>
</div>
    </div>
    <div class="hide-list">
        <div class="semicircle">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div class="post">
    <div class="pjax">
        <article id="post-CNNAutoEncoder" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">卷积自编码器</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            
                <a  data-rel="深度学习">深度学习</a>
            
        </span>
        
        
        <span class="tag">
            
            <a class="color2">AutoEncoder</a>
            
            <a class="color4">CNN</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
        创建时间:<time class="date" title='更新时间: 2019-12-31 00:48:51'>2019-12-23 00:12</time>
        
    </div>
    <div class="article-meta">
        
        
        <span id="busuanzi_container_page_pv">
            阅读:<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-简介"><span class="toc-text">1. 简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-代码"><span class="toc-text">2. 代码</span></a></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h2><ul>
<li><strong>目的：</strong>卷积自编码器创建的目的就在于，利用卷积神经网络的卷积和池化操作，实现特征不变性提取（invariant feature）的无监督特征提取</li>
<li><strong>作用：</strong>卷积自编码器可以用于图像的重构工作。例如，他们可以学习从图片中去除噪声，或者重构图片缺失的部分。<img src="C:%5CUsers%5CCaesar%5CDesktop%5C1.png" alt=""></li>
<li><strong>原理：</strong>这里的原理和卷积差不多，不过这里使用了反卷积操作</li>
</ul>
<h2 id="2-代码"><a href="#2-代码" class="headerlink" title="2. 代码"></a>2. 代码</h2><ul>
<li><p><strong>导入数据</strong></p>
<pre><code>mnist = imput_data.read_data_sets(&apos;MNIST_Labels_Images&apos;,one_hot=&quot;True&quot;)
trainimgs = mnist.train.images
trainlabels = mnist.train.labels
testimgs = mnist.test.images
testlabels = mnist.test.labels
ntrain = trainimgs.shape[0]
ntest = trainimgs.shape[0]
dim = trainimgs.shape[1]
nout = trainlabels.shape[1]
print(&quot;Packages loaded&quot;)</code></pre><p>  shape[0]是查看ndarray行数，shape[1]是查看列数，因为这个数据局一共有55000张图片，每个图片为28*28，所以shape[0]为55000，shape[1]为784</p>
</li>
<li><p><strong>占位符和各层参数</strong></p>
<pre><code>n1 = 16
n2 = 32
n3 = 64
ksize = 5

x = tf.placeholder(tf.float32, [None, dim])
y = tf.placeholder(tf.float32, [None, dim])
keepprob = tf.placeholder(tf.float32)</code></pre><p>  定义每层卷积核的数量，以及尺寸，x为带有噪声的输入数据的占位符，y为原始输入数据的占位符，因为要防止过拟合，所以使用了dropout优化，所以设置了keepprob占位符</p>
</li>
<li><p><strong>权重矩阵和偏置</strong></p>
<pre><code>weights = {
    &apos;ce1&apos;: tf.Variable(tf.random_normal([ksize, ksize, 1, n1], stddev=0.1)),
    &apos;ce2&apos;: tf.Variable(tf.random_normal([ksize, ksize, n1, n2], stddev=0.1)),
    &apos;ce3&apos;: tf.Variable(tf.random_normal([ksize, ksize, n2, n3], stddev=0.1)),
    &apos;cd3&apos;: tf.Variable(tf.random_normal([ksize, ksize, n2, n3], stddev=0.1)),
    &apos;cd2&apos;: tf.Variable(tf.random_normal([ksize, ksize, n1, n2], stddev=0.1)),
    &apos;cd1&apos;: tf.Variable(tf.random_normal([ksize, ksize, 1, n1], stddev=0.1))
}

biases = {
    &apos;be1&apos;: tf.Variable(tf.random_normal([n1], stddev=0.1)),
    &apos;be2&apos;: tf.Variable(tf.random_normal([n2], stddev=0.1)),
    &apos;be3&apos;: tf.Variable(tf.random_normal([n3], stddev=0.1)),
    &apos;bd3&apos;: tf.Variable(tf.random_normal([n2], stddev=0.1)),
    &apos;bd2&apos;: tf.Variable(tf.random_normal([n1], stddev=0.1)),
    &apos;bd1&apos;: tf.Variable(tf.random_normal([1], stddev=0.1))</code></pre><ul>
<li>‘ce1’:尺寸为5*5，通道为1，卷积核数量为n1，因为输入的数据通道为1，所以这里为1，而n1是第一层卷积层卷积核的数量，是由我们自己定义的</li>
<li>‘ce2’:尺寸为5*5，因为上一层卷积层卷积核数量为n1，所以上一次的通道数就变成了n1，所以这里的通道数就为n1，第二层卷积层的卷积核数量为n2,</li>
<li>‘ce3’:与前两个相同</li>
<li><strong>注意：</strong>卷积操作tf.nn.conv2d中的filter(过滤器)参数它的格式为[filter_height, filter_width, in_channels, out_channels]的形式，而反卷积tf.nn.conv2d_transpose中的filter参数，是[filter_height, filter_width, out_channels，in_channels]的形式，注意in_channels和out_channels反过来了！因为两者互为反向，所以输入输出要调换位置</li>
<li>由上可知’cd3’、’cd2’,’cd1’的定义</li>
<li>偏置的定义要与每层的输出通道相同。</li>
</ul>
</li>
<li><p><strong>定义神经网络</strong></p>
<pre><code>def cae(_X, _W, _b, _keepprob):
    _input_r = tf.reshape(_X, shape=[-1, 28, 28,1])

    #Encoder
    _ce1 = tf.nn.sigmoid(tf.add(tf.nn.conv2d(_input_r, _W[&apos;ce1&apos;], strides=[1, 2, 2, 1], padding=&apos;SAME&apos;), _b[&apos;be1&apos;]))
    _ce1 = tf.nn.dropout(_ce1, _keepprob)

    _ce2 = tf.nn.sigmoid(tf.add(tf.nn.conv2d(_ce1, _W[&apos;ce2&apos;], strides=[1, 2, 2, 1], padding=&apos;SAME&apos;), _b[&apos;be2&apos;]))
    _ce2 = tf.nn.dropout(_ce2, _keepprob)

    _ce3 = tf.nn.sigmoid(tf.add(tf.nn.conv2d(_ce2, _W[&apos;ce3&apos;], strides=[1, 2, 2, 1], padding=&apos;SAME&apos;), _b[&apos;be3&apos;]))
    _ce3 = tf.nn.dropout(_ce3 , _keepprob)

    #Decoder
    _cd3 = tf.nn.sigmoid(tf.add(
        tf.nn.conv2d_transpose(_ce3, _W[&apos;cd3&apos;], tf.stack([tf.shape(_X)[0], 7, 7,n2]),strides=[1, 2, 2, 1],
                               padding=&apos;SAME&apos;), _b[&apos;bd3&apos;]))
    _cd3 = tf.nn.dropout(_cd3, _keepprob)

    _cd2 = tf.nn.sigmoid(tf.add(
        tf.nn.conv2d_transpose(_cd3, _W[&apos;cd2&apos;], tf.stack([tf.shape(_X)[0], 14, 14, n1]), strides=[1, 2, 2, 1],
                               padding=&apos;SAME&apos;), _b[&apos;bd2&apos;]))
    _cd2 = tf.nn.dropout(_cd2, _keepprob)

    _cd1 = tf.nn.sigmoid(tf.add(
        tf.nn.conv2d_transpose(_cd2, _W[&apos;cd1&apos;], tf.stack([tf.shape(_X)[0], 28, 28, 1]), strides=[1, 2, 2, 1],
                               padding=&apos;SAME&apos;), _b[&apos;bd3&apos;]))
    _cd1 = tf.nn.dropout(_cd1, _keepprob)
    _out = _cd1

    return _out
print(&quot;Network ready&quot;)
pred = cae(x, weights, biases, keepprob)</code></pre><ul>
<li><p>这个函数输入的数据为(x, weights, biases, keepprob)，所以</p>
<pre><code>_input_r = tf.reshape(_X, shape=[-1, 28, 28,1])</code></pre><p>  这句话的意思就是改变输入数据的形状</p>
</li>
<li><p>编码层就是使用输入数据和每个编码层的权重矩阵进行卷积操作，激活函数为sigmoid函数，然后使用哪个dropout优化，防止过拟合</p>
</li>
<li><p>tf.nn.conv2d_transpose(value,filter,output_shape)</p>
</li>
<li><p>tf.stack()是一个矩阵拼接函数，这里定义了反卷积函数输出的矩阵的形状</p>
</li>
</ul>
</li>
<li><p><strong>损失和优化</strong></p>
<pre><code>pred = cae(x, weights, biases, keepprob)
cost = tf.reduce_sum(
    tf.square(cae(x, weights, biases, keepprob))
                + tf.reshape(y, shape=[-1, 28, 28, 1]))
learning_rate = 0.001
optm = tf.train.AdadeltaOptimizer(learning_rate).minimize(cost)
init = tf.global_variables_initializer()
print(&quot;Functions ready&quot;)
saver = tf.train.Saver(max_to_keep=1)</code></pre><p>  定义损失函数，优化函数，定义初始化函数，定义保存函数，我将我运行的数据保存了，当再次运行时，可以选择直接运行已经跑完的module，也可以从头训练</p>
</li>
<li><p><strong>训练过程</strong></p>
<pre><code>ef my_train():
    with tf.Session() as sess:
        sess.run(init)
        mean_img = np.zeros((784))
        batch_size = 128
        n_epochs = 5

        print(&quot;Strart training&quot;)
        for epoch_i in range(n_epochs):
            for batch_i in range(mnist.train.num_examples // batch_size):
                batch_xs, _ = mnist.train.next_batch(batch_size)
                trainbatch = np.array([img - mean_img for img in batch_xs]) #使batch_xs中的每个图像减去mean_img,并生成ndarray
                # trainbatch = batch_xs
                trainbatch_noisy = trainbatch + 0.3*np.random.randn(trainbatch.shape[0], 784)
                sess.run(optm, feed_dict={x: trainbatch_noisy, y: trainbatch, keepprob: 0.7})

            #saver.save(sess, &apos;./test&apos;, global_step= epoch_i+1)
            print(&quot;[%02d/%02d] cost: %.4f&quot; % (epoch_i, n_epochs, sess.run(cost, feed_dict={x:trainbatch_noisy, y:trainbatch, keepprob: 1.})))</code></pre><p>  训练过程和其他的差不多，里边有一句我不是很理解：</p>
<pre><code>trainbatch = np.array([img - mean_img for img in batch_xs]) #使batch_xs中的每个图像减去mean_img,并生成ndarray
# trainbatch = batch_xs</code></pre><p>  它这里减去了一个自己定义的所有数据为0的ndarray，但是当我使用注释的那一句#trainbatch = batch_xs这一句，也就是使用它的原数据，没使用它的减掉ndarray这个操作，他们得到的cost是差不多的，我感觉没啥用- -</p>
</li>
<li><p><strong>结果展示</strong></p>
<pre><code>if(epoch_i % 1) == 0:
                n_examples = 5
                test_xs, _ = mnist.test.next_batch(n_examples)
                test_xs_noisy = test_xs + 0.3*np.random.randn(test_xs.shape[0], 784)
                recon = sess.run(pred, feed_dict={x: test_xs_noisy, keepprob: 1.})
                fig, axs = plt.subplots(2, n_examples,figsize=(15, 4))
                for example_i in range(n_examples):
                    axs[0][example_i].matshow(np.reshape(test_xs_noisy[example_i, :],(28, 28)), cmap=plt.get_cmap(&apos;gray&apos;))
                    axs[1][example_i].matshow(np.reshape(np.reshape(recon[example_i, ...], (784,)) + mean_img, (28, 28)), cmap=plt.get_cmap(&apos;gray&apos;))
                plt.show()</code></pre><p>  这部分属于plt库，这里总报错，我调<br>  了好久也没解决，所以在代码中被我注释掉了，但是这个并不影响模型的结果，只是不能看见结果，我把书上的结果放到这里看一哈<br><br>  <img src="C:%5CUsers%5CCaesar%5CDesktop%5Ccnn.png" alt=""></p>
</li>
</ul>

      
       
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">赏</a>
</p>






    




    </div>
    <div class="copyright">
        <p class="footer-entry">©2016-2019 Lightman</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full"><span class="min "></span></button>
<button class="post-toc-menu"><span class="post-toc-menu-icons"></span></button>
<div class="post-toc"><span class="post-toc-title">目录</span>
    <div class="post-toc-content">

    </div>
</div>
<a class="" id="rocket" ></a>

    </div>
</div>
<div class="acParent"></div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>喜欢就点赞,疼爱就打赏</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">支付宝</label></span><span><label><input type="radio" name="pay" value="weixin">微信</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.0.1" ></script>

<script src="/js/script.js?v=1.0.1" ></script>
<script>
    var img_resize = 'default';
    /*作者、标签的自动补全*/
    $(function () {
        $('.search').AutoComplete({
            'data': ['#AutoEncoder','#连读发音','#Flex','#CNN','#GAN','#JavaScript','#协作开发软件','#LSTM','#Q网络','#GCN','#Ted','#Vue','#Python','#算法','#沉默的大多数',],
            'itemHeight': 20,
            'width': 418
        }).AutoComplete('show');
    })
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $(".post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        
        $('pre code').each(function(){
            var lines = $(this).text().split('\n').length - 1, widther='';
            if (lines>99) {
                widther = 'widther'
            }
            var $numbering = $('<ul/>').addClass('pre-numbering ' + widther).attr("unselectable","on");
            $(this).addClass('has-numbering ' + widther)
                    .parent()
                    .append($numbering);
            for(var i=1;i<=lines;i++){
                $numbering.append($('<li/>').text(i));
            }
        });
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<style>
    pre{
        position: relative;
        margin-bottom: 24px;
        border-radius: 10px;
        border: 1px solid #e2dede;
        background: #FFF;
        overflow: hidden;
    }
    code.has-numbering{
        margin-left: 30px;
    }
    code.has-numbering.widther{
        margin-left: 35px;
    }
    .pre-numbering{
        margin: 0px;
        position: absolute;
        top: 0;
        left: 0;
        width: 20px;
        padding: 0.5em 3px 0.7em 5px;
        border-right: 1px solid #C3CCD0;
        text-align: right;
        color: #AAA;
        background-color: #fafafa;
    }
    .pre-numbering.widther {
        width: 35px;
    }
</style>

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
        .nav .hide-list.fullscreen {
            left: 492px
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    
    .post .pjax article .article-entry>ol, .post .pjax article .article-entry>ul, .post .pjax article>ol, .post .pjax article>ul{
        border: #e2dede solid 1px;
        border-radius: 10px;
        padding: 10px 32px 10px 56px;
    }
    .post .pjax article .article-entry li>ol, .post .pjax article .article-entry li>ul,.post .pjax article li>ol, .post .pjax article li>ul{
        padding-top: 5px;
        padding-bottom: 5px;
    }
    .post .pjax article .article-entry>ol>li, .post .pjax article .article-entry>ul>li,.post .pjax article>ol>li, .post .pjax article>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    .post .pjax article .article-entry li>ol>li, .post .pjax article .article-entry li>ul>li,.post .pjax article li>ol>li, .post .pjax article li>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    
    .nav-right:before {
        content: ' ';
        display: block;
        position: absolute;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        opacity: 0.3;
        background: url("https://i.loli.net/2019/07/22/5d3521411f3f169375.png");
        background-repeat: no-repeat;
        background-position: 50% 0;
        -ms-background-size: cover;
        -o-background-size: cover;
        -moz-background-size: cover;
        -webkit-background-size: cover;
        background-size: cover;
    }
    

    
</style>







</html>
